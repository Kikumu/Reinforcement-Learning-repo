{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.distributions import Normal\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "import random as rand\n",
    "from itertools import count\n",
    "import time\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self,capacity):   \n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "        \n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count%self.capacity] = experience\n",
    "        self.push_count+=1\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return rand.sample(self.memory,batch_size)\n",
    "    \n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory)>=batch_size\n",
    "    \n",
    "    def update_td_error(self, sampled_experiences):\n",
    "        for sampled_idx,sampled_exp in enumerate(sampled_experiences):\n",
    "            for mem_idx, mem_exp in enumerate(self.memory):\n",
    "                if mem_exp.timestep == sampled_exp.timestep:\n",
    "                    self.memory[mem_idx] = sampled_exp #update memory\n",
    "                    break\n",
    "        \n",
    "    def get_memory_values(self):\n",
    "        return self.memory    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(experiences):\n",
    "    #print(\".....................................................\")\n",
    "    #print(experiences)\n",
    "    batch = Xp(*zip(*experiences))\n",
    "    state = np.stack(batch.state) #stack\n",
    "    action = np.stack(batch.action)\n",
    "    next_state = np.stack(batch.next_state)\n",
    "    reward = np.stack(batch.reward)\n",
    "    done = np.stack(batch.done)\n",
    "    abs_td_error = np.stack(batch.abs_td_error)\n",
    "    timestep = np.stack(batch.timestep)\n",
    "    return state,action,next_state,reward,done,abs_td_error,timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_experiences(state, action, next_state, reward, done, abs_error, timestep):\n",
    "    exp_list = []\n",
    "    for idx_ in range(len(state)):\n",
    "        exp_list.append(\\\n",
    "                        Xp(state[idx_], action[idx_], next_state[idx_], reward[idx_],\\\n",
    "                           done[idx_], abs_error[idx_], timestep[idx_]))\n",
    "    return exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience(state=5, action=6, next_state=7, reward=8, done=9, abs_td_error=10, timestep=11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Xp = namedtuple('Experience',\n",
    "                        ('state', 'action', 'next_state', 'reward', 'done', 'abs_td_error','timestep'))\n",
    "Xp_points = Xp(5,6,7,8,9,10,11)\n",
    "Xp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearApproximator_FCGSAP(nn.Module):\n",
    "    def __init__(self,state_shape,outputs,hidden_dims=(32,32), log_entropy_lr =0.001,\\\n",
    "                log_std_dev_min=-20, log_std_dev_max= 2):\n",
    "        super(linearApproximator_FCGSAP, self).__init__()\n",
    "        self.input_size = state_shape\n",
    "        self.out = outputs\n",
    "        self.log_std_dev_min = log_std_dev_min\n",
    "        self.log_std_dev_max = log_std_dev_max\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available()\\\n",
    "                                   else \"cpu\")\n",
    "        \n",
    "        self.fc1  = nn.Linear(self.input_size,hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_layer = nn.Linear(\\\n",
    "                                hidden_dims[i], hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        \n",
    "        self.output_layer_distribution  = nn.Linear(hidden_dims[-1],self.out)\n",
    "        self.output_layer_mean = nn.Linear(hidden_dims[-1],self.out)\n",
    "        self.target_entropy = -np.prod(self.out)\n",
    "        self.log_alpha = torch.zeros(1,\\\n",
    "                                     requires_grad=True,\\\n",
    "                                     device = self.device)\n",
    "        self.log_alpha_optimizer = torch.optim.Adam([self.log_alpha],\\\n",
    "                                                    lr=log_entropy_lr)\n",
    "                                     \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state_shape):\n",
    "        if not isinstance(state_shape, torch.Tensor):\n",
    "            state_shape = torch.tensor(state_shape, dtype=torch.float32)\n",
    "        state_shape = state_shape.to(self.device)\n",
    "        x = self.fc1(state_shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = F.relu(hidden_layer(x))\n",
    "        \n",
    "        distribution = self.output_layer_distribution(x)#logits, preferences of actions\n",
    "        distribution = torch.clamp(distribution,\\\n",
    "                                   self.log_std_dev_min,\\\n",
    "                                   self.log_std_dev_max)\n",
    "        mean   = self.output_layer_mean(x)\n",
    "        return mean, distribution\n",
    "        \n",
    "    def full_pass(self, state, epsilon = 1e-7):\n",
    "        mean, distribution = self.forward(state)\n",
    "        pi_s = Normal(mean, distribution.exp())\n",
    "        pre_sampled_actions = pi_s.rsample()\n",
    "        sampled_actions = torch.tanh(pre_sampled_actions)#scale actions between -1 and 1\n",
    "        #we also rescale our logprobs to match action space\n",
    "        log_probs = pi_s.log_prob(pre_sampled_actions) - torch.log(\\\n",
    "                                    (1 - sampled_actions.pow(2)).clamp(0,1) + epsilon)\n",
    "                                                \n",
    "        log_probs = log_probs.sum(dim=1, keepdim=True)\n",
    "        return sampled_actions, log_probs, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearApproximator_FCQV(nn.Module):#Q value of state action pair\n",
    "    def __init__(self,state_shape,action_outputs_size,hidden_dims=(32,32)):\n",
    "        super(linearApproximator_FCQV, self).__init__()\n",
    "        self.input_size = state_shape\n",
    "        self.action_outputs_size = action_outputs_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available()\\\n",
    "                                   else \"cpu\")\n",
    "        \n",
    "        self.fc1  = nn.Linear(self.input_size,hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_input_layer = hidden_dims[i]\n",
    "            if i == 0:\n",
    "                hidden_input_layer += self.action_outputs_size #increased to account for size/number of actions\n",
    "            hidden_layer = nn.Linear(\\\n",
    "                                hidden_input_layer, hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        \n",
    "        self.output_layer  = nn.Linear(hidden_dims[-1],1)\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, state_shape, action_shape):\n",
    "        if not isinstance(state_shape, torch.Tensor):\n",
    "            state_shape = torch.tensor(state_shape, dtype=torch.float32).to(self.device)\n",
    "        if not isinstance(action_shape, torch.Tensor):\n",
    "            action_shape = torch.tensor(action_shape, dtype=torch.float32).to(self.device)\n",
    "                    \n",
    "        x = self.fc1(state_shape)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        for idx, hidden_layer in enumerate(self.hidden_layers):\n",
    "            if idx == 0:\n",
    "                x = torch.cat((x, action_shape), dim=1)\n",
    "            x = F.relu(hidden_layer(x))\n",
    "        \n",
    "        q_value = self.output_layer(x)#logits, preferences of actions\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_networks(online_q_network_a, online_q_network_b,\\\n",
    "                    offline_q_network_a, offline_q_network_b, tau):\n",
    "        \n",
    "    for target_weights, online_weights in zip(offline_q_network_a.parameters(), online_q_network_a.parameters()):\n",
    "        target_weight_update = (1.0 - tau)*target_weights.data\n",
    "        online_weight_update = tau*online_weights.data\n",
    "        sum_up = target_weight_update + online_weight_update\n",
    "        target_weights.data.copy_(sum_up)\n",
    "        \n",
    "    for target_weights, online_weights in zip(offline_q_network_b.parameters(), online_q_network_b.parameters()):\n",
    "        target_weight_update = (1.0 - tau)*target_weights.data\n",
    "        online_weight_update = tau*online_weights.data\n",
    "        sum_up = target_weight_update + online_weight_update\n",
    "        target_weights.data.copy_(sum_up)\n",
    "\n",
    "    return offline_q_network_a, offline_q_network_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritize_samples(experience_samples, alpha, beta):\n",
    "    state,action,next_state,reward,done,abs_td_error,timesteps \\\n",
    "                            = extract_tensors(experience_samples)\n",
    "    abs_td_error, indices_ = (list(t) for t in zip(*sorted(\\\n",
    "                            zip(abs_td_error.tolist(), timesteps))))\n",
    "    abs_td_error.reverse()\n",
    "    indices_.reverse()#reverse to march sort func\n",
    "    abs_td_error = np.array(abs_td_error)\n",
    "    abs_td_error  = torch.tensor(abs_td_error)\n",
    "    ranks = np.arange(1, len(abs_td_error)+1)\n",
    "    priorities = 1.0/ranks\n",
    "    priorities = priorities**alpha\n",
    "    priorities = np.expand_dims(priorities, axis=1)\n",
    "    probabilities = priorities/np.sum(priorities, axis=0)\n",
    "    assert np.isclose(probabilities.sum(), 1.0)\n",
    "    number_of_samples  = len(probabilities)\n",
    "    weight_importance_ = number_of_samples*probabilities\n",
    "    weight_importance_ = weight_importance_**-beta\n",
    "    weight_importance_max = np.max(weight_importance_)\n",
    "    weight_importance_scaled = weight_importance_/weight_importance_max\n",
    "    return weight_importance_scaled, indices_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_online_model(experience_samples,\\\n",
    "                        online_policy_network, online_q_network_a, online_q_network_b,\\\n",
    "                        online_policy_optimizer, online_q_optimizer_a, online_q_optimizer_b,\\\n",
    "                        offline_q_network_a, offline_q_network_b,\\\n",
    "                        gamma, weighted_importance,\\\n",
    "                        timestep_indices):\n",
    "    \n",
    "    states, actions, next_states, rewards, done, td_errors, timesteps = extract_tensors(experience_samples)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #rearrange first\n",
    "    #need to find indexes of timestep indexes in timestep.\n",
    "    #then rearrange according to those indexes\n",
    "    sort_values = [timesteps.tolist().index(i) for i in timestep_indices]\n",
    "    states = states[sort_values,:]\n",
    "    states = np.squeeze(states)\n",
    "    actions = actions[sort_values]\n",
    "    next_states = next_states[sort_values,:]\n",
    "    next_states = np.squeeze(next_states)\n",
    "    rewards = rewards[sort_values]\n",
    "    done = done[sort_values]\n",
    "    td_errors = td_errors[sort_values]\n",
    "    timesteps = timesteps[sort_values] \n",
    "    \n",
    "    \n",
    "    states = torch.tensor(states).float().to(device)\n",
    "    actions = torch.tensor(actions)\n",
    "    actions = actions.float().to(device)\n",
    "    next_states=torch.tensor(next_states).float().to(device)\n",
    "    rewards = torch.tensor(rewards).float().to(device)\n",
    "    rewards = rewards.unsqueeze(1)\n",
    "    done = torch.tensor(done).float().to(device)\n",
    "    done = done.unsqueeze(1)\n",
    "    weighted_importance = torch.tensor(weighted_importance).float().to(device)\n",
    "    \n",
    "    \n",
    "    current_actions,log_pi, _ = online_policy_network.full_pass(states)\n",
    "    target_alpha = (log_pi +\\\n",
    "                    online_policy_network.target_entropy).detach()\n",
    "    \n",
    "    target_alpha_loss = -(online_policy_network.log_alpha *\\\n",
    "                         target_alpha).mean()\n",
    "    \n",
    "    online_policy_network.log_alpha_optimizer.zero_grad()\n",
    "    target_alpha_loss.backward()\n",
    "    online_policy_network.log_alpha_optimizer.step()\n",
    "    optimized_alpha = online_policy_network.log_alpha.exp()\n",
    "    \n",
    "    \n",
    "    max_q_sa_online_a = online_q_network_a(states,\\\n",
    "                                           current_actions.detach())\n",
    "    max_q_sa_online_b = online_q_network_b(states,\\\n",
    "                                           current_actions.detach())\n",
    "    max_q_online__ = torch.min(max_q_sa_online_a,\\\n",
    "                               max_q_sa_online_b)\n",
    "    \n",
    "    policy_loss = -(max_q_online__.detach()\\\n",
    "                    - optimized_alpha*log_pi).mean()#policy loss\n",
    "    \n",
    "    predicted_online_action_policy,\\\n",
    "                log_pi_ns, _ = online_policy_network.full_pass(next_states)\n",
    "    max_q_sa_offline_a = offline_q_network_a(next_states,\\\n",
    "                                predicted_online_action_policy)\n",
    "    max_q_sa_offline_b = offline_q_network_b(next_states,\\\n",
    "                                predicted_online_action_policy)\n",
    "    max_q_sa_offline = torch.min(max_q_sa_offline_a,\\\n",
    "                                 max_q_sa_offline_b)\n",
    "    \n",
    "    max_q_sa_offline = max_q_sa_offline - optimized_alpha*log_pi_ns\n",
    "    TWIN_target = max_q_sa_offline\n",
    "    #print(\"w_i: \", weighted_importance,weighted_importance.shape)\n",
    "    #print(\"rwd: \", rewards,rewards.shape)\n",
    "    #print(\"abs: \", td_errors,td_errors.shape)\n",
    "    TWIN_target = TWIN_target.detach()\n",
    "    TWIN_target *=(1 - done)\n",
    "    TWIN_target = rewards + gamma*TWIN_target\n",
    "    TWIN_target*=weighted_importance.detach()\n",
    "    TWIN_target = TWIN_target.detach()\n",
    "    loss_func = torch.nn.SmoothL1Loss()\n",
    "    \n",
    "    \n",
    "    q_sa_online_a = online_q_network_a(states, actions)\n",
    "    q_sa_online_a*=weighted_importance.detach()\n",
    "    q_sa_online_b = online_q_network_b(states, actions)\n",
    "    q_sa_online_b*=weighted_importance.detach()\n",
    "    \n",
    "    #update errors\n",
    "    abs_a = (TWIN_target - q_sa_online_a.detach())\n",
    "    abs_b = (TWIN_target - q_sa_online_b.detach())\n",
    "    ovr_abs_update = torch.min(abs_a, abs_b)\n",
    "    ovr_abs_update = np.absolute(ovr_abs_update.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "    q_online_value_loss_a = loss_func(q_sa_online_a,\\\n",
    "                                             TWIN_target.detach())\n",
    "    q_online_value_loss_b = loss_func(q_sa_online_b,\\\n",
    "                                             TWIN_target.detach())\n",
    "    online_q_optimizer_a.zero_grad()\n",
    "    q_online_value_loss_a.backward()\n",
    "    online_q_optimizer_a.step()\n",
    "    \n",
    "    online_q_optimizer_b.zero_grad()\n",
    "    q_online_value_loss_b.backward()\n",
    "    online_q_optimizer_b.step()\n",
    "    \n",
    "    online_policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    online_policy_optimizer.step()\n",
    "        \n",
    "    states, actions, next_states, rewards, done, td_errors, timesteps = extract_tensors(experience_samples)\n",
    "    experiences_rebuilded = rebuild_experiences(states, actions, next_states, rewards, done, ovr_abs_update, timesteps)\n",
    "    return experiences_rebuilded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_error(online_policy_network, offline_q_network_a, offline_q_network_b,\\\n",
    "                online_q_network_a, online_q_network_b, state, action, next_state, reward, gamma):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    state = torch.tensor(state).float().to(device)\n",
    "    state = state.unsqueeze(0)\n",
    "    next_state = torch.tensor(next_state).float().to(device)\n",
    "    next_state = next_state.unsqueeze(0)\n",
    "    alpha = online_policy_network.log_alpha.exp()\n",
    "    ns_actions,log_pi_ns, _ = online_policy_network.full_pass(next_state)\n",
    "    q_target_next_states_action_a = offline_q_network_a(next_state,\\\n",
    "                                                    ns_actions.detach())\n",
    "    q_target_next_states_action_b = offline_q_network_b(next_state,\\\n",
    "                                                    ns_actions.detach())\n",
    "    TWIN_target = torch.min(q_target_next_states_action_a, q_target_next_states_action_b)\n",
    "    TWIN_target = TWIN_target - alpha * log_pi_ns\n",
    "    TWIN_target = reward + (gamma*TWIN_target.detach())\n",
    "    action = np.expand_dims(action, axis=0)\n",
    "    q_online_state_action_val_a = online_q_network_a(state, action)\n",
    "    q_online_state_action_val_b = online_q_network_b(state, action)\n",
    "    abs_a = (TWIN_target - q_online_state_action_val_a)\n",
    "    abs_b = (TWIN_target - q_online_state_action_val_b)\n",
    "    abs_stack = torch.min(abs_a, abs_b)\n",
    "    ovr_abs_update = abs_stack\n",
    "    return np.absolute(ovr_abs_update.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, online_policy_network, env, warm_up, batch_size, memory):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    state = torch.tensor(state).float().to(device)\n",
    "    state = state.unsqueeze(0)\n",
    "    warm_up_action = batch_size * warm_up\n",
    "    if memory.can_provide_sample(warm_up_action) == False:\n",
    "        action = np.random.uniform(low=env.action_space.low, high=env.action_space.high)\n",
    "        action = action.reshape(env.action_space.high.shape)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            mean,log_std = online_policy_network.forward(state)\n",
    "            action = torch.tanh(Normal(mean, log_std.exp()).sample())\n",
    "            action = action.detach().cpu().numpy().reshape(env.action_space.high.shape)\n",
    "            #print(\"action: \",action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean().detach().cpu().numpy())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAC_PER(env,\n",
    "         gamma=0.99,\n",
    "         alpha_pr=0.3,\n",
    "         beta_pr=0.6,\n",
    "         memory_size = 50000,\n",
    "         tau = 0.001,\n",
    "         offline_update = 1,\n",
    "         min_sample_size=400,\n",
    "         batch_size = 64,\n",
    "         n_ep=200,\n",
    "         max_steps = 100000,\n",
    "         max_steps_per_ep = 500,\n",
    "         warm_up=50\n",
    "         ):\n",
    "    \n",
    "    \n",
    "    observation_space = len(env.reset())\n",
    "    action_space_high, action_space_low = env.action_space.high, env.action_space.low\n",
    "    n_actions = len(action_space_high)\n",
    "    online_policy_network = linearApproximator_FCGSAP(observation_space,n_actions,\\\n",
    "                                     hidden_dims=(256,256))\n",
    "    online_q_network_a = linearApproximator_FCQV(observation_space,\\\n",
    "                                     n_actions,hidden_dims=(256,256))\n",
    "    online_q_network_b = linearApproximator_FCQV(observation_space,\\\n",
    "                                     n_actions,hidden_dims=(256,256))\n",
    "    \n",
    "    offline_q_network_a = linearApproximator_FCQV(observation_space,\\\n",
    "                                     n_actions,hidden_dims=(256,256))\n",
    "    offline_q_network_b = linearApproximator_FCQV(observation_space,\\\n",
    "                                     n_actions,hidden_dims=(256,256))\n",
    "    \n",
    "\n",
    "    offline_q_network_a.eval()\n",
    "    offline_q_network_a = freeze_model(offline_q_network_a)\n",
    "    offline_q_network_b.eval()\n",
    "    offline_q_network_b = freeze_model(offline_q_network_b)\n",
    "    \n",
    "    online_policy_optimizer    = torch.optim.Adam(online_policy_network.parameters(),lr=0.0003)\n",
    "    online_q_optimizer_a = torch.optim.Adam(online_q_network_a.parameters(),lr=0.0005)\n",
    "    online_q_optimizer_b = torch.optim.Adam(online_q_network_b.parameters(),lr=0.0005)\n",
    "    \n",
    "    memory = ReplayMemory(memory_size)\n",
    "    \n",
    "    t_step = 0 #important\n",
    "    reward_per_ep = []\n",
    "    \n",
    "    \n",
    "    for e in tqdm(range(n_ep)):\n",
    "        state = env.reset()\n",
    "        reward_accumulated = 0\n",
    "        \n",
    "        while True:\n",
    "            env.render()\n",
    "            action = select_action(state, online_policy_network, env, warm_up, batch_size, memory)\n",
    "            #if memory.can_provide_sample(min_sample_size):\n",
    "                #print(action)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            td_error = query_error(online_policy_network, offline_q_network_a, offline_q_network_b,\\\n",
    "                                online_q_network_a, online_q_network_b,\\\n",
    "                                state, action, next_state, reward, gamma)\n",
    "            td_error = np.squeeze(td_error, axis = 0)\n",
    "            reward_accumulated+=reward\n",
    "            is_truncated = 'TimeLimit.truncated' in info and\\\n",
    "                                info['TimeLimit.truncated']\n",
    "            is_failure = done and not is_truncated\n",
    "           \n",
    "            memory.push(Xp(state, action, next_state, reward, is_failure, td_error, t_step))\n",
    "            state = next_state\n",
    "            t_step+=1\n",
    "            if memory.can_provide_sample(min_sample_size):\n",
    "                experience_samples = memory.sample(batch_size)\n",
    "                weighted_importance, indices = prioritize_samples(experience_samples, alpha_pr, beta_pr)\n",
    "                rebuilded_exp = update_online_model(experience_samples,\\\n",
    "                        online_policy_network, online_q_network_a, online_q_network_b,\\\n",
    "                        online_policy_optimizer, online_q_optimizer_a, online_q_optimizer_b,\\\n",
    "                        offline_q_network_a, offline_q_network_b,\\\n",
    "                        gamma, weighted_importance, indices)\n",
    "                memory.update_td_error(rebuilded_exp)\n",
    "                \n",
    "            if t_step%offline_update == 0:\n",
    "                offline_q_network_a, offline_q_network_b = update_networks(online_q_network_a, online_q_network_b,\\\n",
    "                                                                    offline_q_network_a, offline_q_network_b, tau)\n",
    "            if done == True:\n",
    "                reward_per_ep.append(reward_accumulated)\n",
    "                break\n",
    "            if t_step % max_steps_per_ep == 0:\n",
    "                #plot_grad_flow(online_policy_network.named_parameters())\n",
    "                break\n",
    "            if t_step > max_steps:\n",
    "                env.close()\n",
    "                return reward_per_ep\n",
    "    env.close()           \n",
    "    return online_policy_network,reward_per_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BipedalWalker-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-52b408cb3070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAC_PER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-7767b2eda56c>\u001b[0m in \u001b[0;36mSAC_PER\u001b[0;34m(env, gamma, alpha_pr, beta_pr, memory_size, tau, offline_update, min_sample_size, batch_size, n_ep, max_steps, max_steps_per_ep, warm_up)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mexperience_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mweighted_importance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprioritize_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperience_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 rebuilded_exp = update_online_model(experience_samples,\\\n\u001b[0m\u001b[1;32m     74\u001b[0m                         \u001b[0monline_policy_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline_q_network_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline_q_network_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                         \u001b[0monline_policy_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline_q_optimizer_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline_q_optimizer_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-5674f868a005>\u001b[0m in \u001b[0;36mupdate_online_model\u001b[0;34m(experience_samples, online_policy_network, online_q_network_a, online_q_network_b, online_policy_optimizer, online_q_optimizer_a, online_q_optimizer_b, offline_q_network_a, offline_q_network_b, gamma, weighted_importance, timestep_indices)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcurrent_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monline_policy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     target_alpha = (log_pi +\\\n\u001b[0m\u001b[1;32m     38\u001b[0m                     np.expand_dims(online_policy_network.target_entropy, axis=0)).detach()\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_alpha shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monline_policy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_alpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "pn, rewards = SAC_PER(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = uniform_filter1d(rewards, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i,e in enumerate(arr):\n",
    "    y.append(i)\n",
    "    x.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2892a7b490>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABVBUlEQVR4nO29eZhjZ3nmfT9ajnaVau+uqrZ7s9vubtvYbrywBYiJzWZjEhKTkIRrYMhkmJB9Al+2mWtCMvkmK0kg8UcCyZBACJsdHEywjXEw2KbbS+/d7sXdXfte2pcjvd8f57xHRyodSWdRaXt/19WXXZLq6FVJes597vdZiDEGgUAgEPQXrnYvQCAQCARbjwj+AoFA0IeI4C8QCAR9iAj+AoFA0IeI4C8QCAR9iKfdC2iWkZERtnPnznYvQyAQCLqKI0eOLDPGRqtv75rgv3PnThw+fLjdyxAIBIKugogu1bpd2D4CgUDQh4jgLxAIBH2ICP4CgUDQh4jgLxAIBH2ICP4CgUDQh4jgLxAIBH2ICP4CgUDQh4jgL+hpnj63jGPTG+1ehkDQcYjgL+hpfuWLL+IDf/8DJLKFdi9FIOgoRPAX9CwL8SwW4jksJnL402+93O7lCAQdha3gT0TvIaITRFQiokNV932MiM4R0Rkiulu9bQcRfZuITqq/94t2nl8gqAe3e26aGsDff/8VnJqLt3lFAkHnYFf5HwfwbgBP6W8kov0AHgBwAMA9AD5JRG4AMoBfZYztB3AHgA+rjxUIHOfozAZcBPz1T9+KgYAXv/W14yiVxNhSgQCwGfwZY6cYY2dq3HUfgC8wxnKMsYsAzgG4jTE2xxh7Xv3dBIBTACbtrEEgMOLY9DquGYtg+0AAH33rdThyaQ3/enS23csSCDqCVnn+kwCu6H6eRlWQJ6KdAG4G8GyL1iDoYxhjODazgRumBgAAP3bLFAYCXjx3cbXNKxMIOoOGLZ2J6DEA22rc9ZuMsYesPCkRhQF8GcAvMcYMjVgi+hCADwHAVVddZeWpBH3K3EYWy8k8blSDv8tFmBoMYGY90+aVCQSdQcPgzxi7y8JxZwDs0P08pd4GIvJCCfz/yBj7SoPnfhDAgwBw6NAhYdYKDPn60Vn8w/cu4XMfvB2Sx4Wj6mbvDZMD2mMmYgG8spxq1xIFgo6iVbbPwwAeICIfEe0CcA2A54iIAPwtgFOMsT9p0XML+pDnL63juVdW8W/H5gAAx2bW4XERrt8e1R4zGQtgdj0DxoSOEAjspnreT0TTAO4E8AgRfRMAGGMnAHwRwEkAjwL4MGOsCOC1AH4awJuJ6EX139tsvQKBAEAqJwMA/u7pi6rfH8c14xH4vW7tMVODAaTyRWxkRMGXQGBrjCNj7KsAvmpw38cBfLzqtu8CIDvPKRDUIplXgv/R6Q0cvrSGY9Pr+JH9lVtVk7EAAGB6LYNYUNryNQoEnYSo8BX0BKmcjGvGwhgIePF7Xz+JtXRBy/ThTA4qwV9s+nYuv/vQcXzsK8favYy+oGsGuAsE9UhmZYxGfLhr/zg+9eR5ANAyfThc+c+sieDfqTz3yhrycrHdy+gLhPIX9ATJnIyQz4OfufNqeFwEr5uwb1uk4jFDIQl+r0so/w5mKZHDUiLX7mX0BUL5C3qCVF5GxOfB9oEAfuLVOzC/kYXP4654DBFhQs34EXQexRLDaiqHEgOyhWLFZr3AeUTwF/QEyayi/AHg4/ffYPi4yZgo9OpUVlN58NZLS4kcdgwF27ugHkfYPoKeIJUrasG/HlODAeH5dyjLybLds5QU1k+rEcFf0PXk5CLyxRLCvsY2wWQsgJVUHpm82FTsNCqCv/D9W44I/oKuJ5VTAnm4CeUv0j07F33AF8G/9YjgL+h6eHVvM7bPZEzxkcWmb+chlP/WIjZ8BV1PUg3+zSj/iZgfgFD+nchyMg+fx4WwzyM8/y1ABH9B18OVf9jf+OO8LeqH20Vi07cDWUrkMBL2IeL3YDEugn+rEcFf0PUkTNg+HrcL26J+ofw7kOVkDiMRH6J+ofy3AuH5C7qelAnbB1Bz/YXy7ziWEjmMhn0YjfiwLDz/liOCv6DrMbPhCygZP0L5dx7LyRxGIxJGIz4sJXJi7kKLEcFf0PUksuaV/3w8C7lYauWyBCZQWjvkFeUf9iFfLCGekdu9rJ5GBH9B18Pz/ENSc71gJgcDKJYYFoS10DGsqD19RiI+jEWVjKzFRLbNq+ptRPAXdD2pvAy/1wWPu7mP84Ro7dxxLCfyAIARVfkDIte/1YhsH0HXk8zJTVs+ADCp5vrPbYjg3ynwAq/RiA+D6pQ1kfHTWkTwF3Q9yay54B/xe5XfywlPuVPgKn8k7MNQSKq4TdAaRPAXdD2pnNx0pg8ArU+8aO7WOXDlPxKWEPZ5IHlcIvi3GOH5C7qepMngH5RE8O80lpM5+L1KawciwljEh0UR/FuKCP6CrieZU6Z4NYvX7YLXTUgXRPDvFHhrByICAC3Xv1U8cXoB2T5//0XwF3Q9Zm0fAAh43UL5dxDLyTxGIz7t59Fw64L/+aUk/tNnD+ORo3OOHXMtlXfsWFuFCP6CrifZ5BQvPQFJBP9OYjmpKH/OaMTXsmyfK6tpAHDMVjr8yipu+b1v4aUr644cb6sQwV/Q9aRyclNTvPQEJY+wfToIbvtwRiM+rKbyKLSgCntuQykeW005E/w/98wlMAa8spJy5HhbhQj+gq5GLpaQKRQR9nlN/Z5i+4hUz05ALpawmq60fcYiSi3GcgvU/5za12nFAatmI13AN47PK8dLdpf1Yzv4E9F7iOgEEZWI6FDVfR8jonNEdIaI7q66z01ELxDR1+2uQdC/pFTrJmRS+QckNzJC+XcEq6k8GANGw5J2Gz8RLCVyKJYYPvXkeVxeSTvyfLOq8nfCp3/opRnkZOXqZC3dZ8EfwHEA7wbwlP5GItoP4AEABwDcA+CTRKT/hv4igFMOPL+gjzHbzpkTlNxIC8+/I1hKlgu8OPrg/8f/fgZ/+OhpPPTijCPPxyu7Vx0I/v/8gys4MBHFcEhy5EpiK7Ed/BljpxhjZ2rcdR+ALzDGcoyxiwDOAbgNAIhoCsDbAXza7vML+pukiSleekS2T+ewrNolFdk+6v9//rkr+OST5wE4Y9MAwNx61pHjHZ/ZwInZOH7i1TswGJK6LuOnlZ7/JIArup+n1dsA4M8A/HcAoqeuwBZJk738OUL5dw761g6cEdUCeuzUAm6cGsBkLOBI8GeMYdYh5f/PP7gCn8eF+26axFCvKn8ieoyIjtf4d5/ZJySidwBYZIwdaeKxHyKiw0R0eGlpyexTCfoAq7aP8Pw7B31TN47P48Zg0IvBoBef/KlbsG3AjxUHNn/X0wVkCyUMhySk80XLhV55uYSvvTiDtx7choGgF0PB7lP+TX1jGGN3WTj2DIAdup+n1NvuBXAvEb0NgB9AlIg+xxh7X43nfRDAgwBw6NAhMdZHsAltipdk1vbxCNunQ1hO5BDwujddvf3+/Tdgx1AQU4NBDIckXHJgw5er/gOTA3jq7BJWUnlMqi2+Ta05mUMiK+P23cMAgKGwhB+80l3Bv5W2z8MAHiAiHxHtAnANgOcYYx9jjE0xxnZC2RB+olbgFwiagU/xipj0/BXbRxajAjuAuY0stg/4N93+1hu24+DkAABgOOxzxFbhfv/BiSgAYNViemY8WwAADASUFOOhoIS1dB6lUvd8npxI9byfiKYB3AngESL6JgAwxk4A+CKAkwAeBfBhxpiQWgJHMTu/lxOQ3CgxaGl6gvZxZS2NycH66nskLGE1lbMdXHmmDz+prFpMz9xIVwX/kIQSAzYyBVvr20qcyPb5qqrkfYyxccbY3br7Ps4Y28MY28cY+0aN332SMfYOu2sQ9C+W8/zVts793tyrE5hey2BqMFj3McNqcF23GVxnN7LwugnXjkcAWK/y5UFeH/wB6yeTdiAqfAVdTSIrw+sm+Dxm2zsojxcZP+0llZOxmspjqoHyH1Izgexu+s6tZzAe9WujIq1W5cZVuzHqrwr+XbTpK4K/oKtJmRzhyAmI4N8RzKitFnYM1Vf+I2pwtev7z25kMTEQQDTggcdFloO1ofIXwV8g2BqstHMGlMZugBjo0m6m15QMnkbKf9imUufMbWSwPeYHEWEwJNkK/kTlRAMR/AUCB3ni9ALOLSbqPsbs8HYO9/zbnev/wuU1LXOkH5leU5R/4+DPlb9126dUYpjfyGL7gPJcdloyxDMFhH0euFzK8BkR/AUCB/m1fzmKTz15oe5jLAd/zfZpT2dPxhg+8fjLuP+T38Nnn36lLWvoBKbXMvB5XJoHb8RgUAJRuRWEFZZTORSKDBMxv3ZMq8E6nilolg+gzIUOSm4R/AUCu8jFElZT+YbZGNZtn/bN8ZWLJfzm147jT751FkA5/bAfmVbTPPn4RiPcLsJgULK14Tur5vhz5T8Utl6Vu1EV/AHlZNJNVb4i+As6kjU1j7qRkrKq/NuZ7fPbDx3HPz17GT//xj24fnsUi/H+HVR+ZbVxmidn2IZHD5T7+POCMju2z0amoGX6aOsLd1d/HxH8BR0J743eKG86mZNN5/gDrfP8D7+yijf90ZNI1PHxnzq7jLsPjOM37rkOYy0cV9gNTK+lG/r9nOGwZGvDl/fxn1DbOQyFJGxkCpamhcWztZW/sH0EApvwL3mj8vtUzvwUL6Ds+Ttt+5yai+PicqpuH5p0XsZ4VFGfYxFfS5T/SjKHD3z2B440Q2sVyZyMtXTBRPD3YdnGhu/curK/MBhUPi/D6iatlSEstWwfu1cmW40I/oKOhH+JUnU6LzLGkMqbn98LlFM9nbZ9+JXEUp3h4Kl8UXv+0YgPy0n7bQuqee7iKh4/vYhjMxuOHtdJZtRMnx1N2j4jIXvKf24ji4lYeX9hKKRsMlsJ2BuZAqKBSrvRTupoOxDBX9CR6Dd6jZRZOl8EY+b7+gDKBqLkcSFdcDbbJ5NXLITFRLbm/YViCXm5pO05jEV8kEvM8RGAvHgqlevcOoZmc/w5QyGfZZsGUDp66hvIaemZJk8oObmIbKG0SfkPhSRkCsWuqR3p+eB/ZTWN2fX+zaboVlZTBd3/1/5yWp3ixQl43ci2SPkbWTn8SoMH/1F1ULnTvn85+HfukPpyjn+TG75qrr/VjJq59XKOv/54Zjdp4xnlb1or+APd09+n54P/+z/zHD7+SO+NCv74IyfxF4+/3O5ltAy98m8Y/C0of6A107y4RbVoYPvwugJ+tTIWVawHp31/bqkkOzr4p+HzuLSpXY3gj7OS618sMSwmKltHDwatef68tUPUIPh3S7pnzwf/oORpWyFPK/nO2SX8x7nldi+jZayk8nCr1ZNGwd/qIBdOQHIj7XC2D7/kN7J9uA2jKf9weVC5k3SL8p9qIsefo7V4sLDpu5rKo8TKJ1sA2sav2X2ERsG/W9I9ez74B7y9Oas1mZUR76Le4WZZTeVxtdrsy1D5Z6318ucEpRbaPo2Uv27Dt97jrcKtzmQHC58ra+mmLR/AXgsFfnLVVxJ73C7Egl7Tx6se5FK9PqH8O4RendWayMnaFKteZDWVx66REIiMv0zc0jA7xYvTCmHQtOevZiiFfB6EJLejyj+dl7UiuW5Q/s0yombnWLF9lmrMCQaUgG06+GcMgn9QKP+OIii5u2b3vVkYY0jm5J5uCLaaymMk7FNK+g2+TAmbyj8geRy3fbK6VM9aIyKrlT8AjEX9hjaRFfQJDp2a7ZPIFrCeLphS/rwNs5XaBU35VwV/pcrX3PE026eqwncg4IWrjlhplkS2gL/5znnLWU3N0vPBP9CCTb12w1Mckzm5q2aGNgtjSurjUFjCYNBruCG3oAbM8Wj9pmBGBL1uZBy2RbjQyBdLNUf68WCsr0oeDfscVf48iwbo3A1fvidhRvkTkeUqX/73HQkbK3/GWFP7g0bK38X7D9kM/l8/Ooc/+MZpPHV2ydZxGtHzwT/Yg7YP/0IzBqQ62NO1Sjwro1BkGA5JGA75DL/sc+tZDAS8WsGUWVrx2dAfr5aPz4NLQLfmUYdbPPDAOhkLdJzts5bK49JKCodfWQPQeIhLNcMha4Pcl5M5BCX3pqvEoZBPC/4ff+QUbvv44w2dgo1MAQGvG5Jnc/gcCtlv7sYL8753fsXWcRph7VvTRSi+bmd9Aeyi9/rjWRkRv/n2Bp0M//IMhSQMhry4uJyq+bi5qqIds/hbYAlmCkUlmCdyWIzntFmxHE35SzrlH/HhqbPOBf/Z9Qw8LsLu0VBHJQW8eGUd7/qrp7WfXQRcZTb4h83bNICi/KstH0CxfdbSBXz5yDQ+/d2LAID5eBa7RkKGx6pV3ctxosr3uBr8n25xNl/vB3/Jg2yhhFKJaYMXuh39pbzSQKz5S+duYEUX/IdCPhy5tFbzcXMbWVvBP9iCDd9svoirh4JYSuSwlNzs43MhEqxS/omcjEy+qPUcssPMWgbbBvyI+r0dVeD43EVFyf7+/TcgGvBgajCoZcg0y3BIqts3yYilRK7mzIDBkIRiieGjXzmqnbQXGgT/eEbeZPno1/fyYtL0+jh5uYTTcwkEJTdOzyewksxpKa5O0xe2DwBk5d6xfpJ65Z/prasaoJzKpwR/L9bShZp7G3MbWWyPWT/xcdun1sasVTKFIq4aVtRsrYyfVL4Ir5sqLIOxiLO5/jPrGUzEAgj53B214XtsJo6JAT9+8var8I4bJ/CqHTHTxxgO+6xt+CaNlT+g7AX8xXtvBgAsxOtvvtdq6saxq/zPLiSQL5bwwKuvAgA8c2HV8rEa0TfBv5c2fZO58qV8vdbB3Qqv7uXKv1himzKbsoUiVlN5TNhQ/gHJA8aAnOxcVkWmUMRo2Ieg5K7t+efkTXsUPCjVulKwwux6FlOxAEI+T0d5/idmNnBwcsDWMYbDUt1mf0YY2T4HJwewdyyMv37frdg/EQXQuNq6XvAfDklYT+dRtJiIwS2fn7x9B8I+D54+3zrrp+eDv9/bvolNraLS8+/+4P/yQgKPHp/XfuZ9fYZDPk2ZVW/yzau92bcNWFf+Aa/y8XdKGJRKDNlCCX6vW2nVXCP4p/LFCr8fAMbU/j5OtHiQiyXMx7OYHAwg7PMglZcdvbKxSiJbwIXllO3gz3P9zWz65uQiNjKFmrbP3rEwHvuVH8JNO2KI+Dzwe11NKf/qNE/OYFBCiQHrFvv7HJvZQMTnwe6RMG7fNYTvt3DTt+eDf28qf73n3znKzip/9/Qr+MgXXtDymldTOQS8bgQkNwYNqiZn1dGHdpR/ua2zM39DfgURkNwYi/ixWCOIZPJFBH1Gyt9+8J+PZ1EsMdX28aDE2j+kHgBOzSUAAAcno7aOo7VQMPG34tliIzWUvx4iwnjUj4UG9ls8W9jU2oHDrx4eP7XY9Pr0HJ/ZwIHJKFwuwmv2juDicqpl+zZ9FPy7P0hyKj3/7lf+8WwBebmE80vKRtlKKq99yY2U/xyfx2rD868e6PLtM4u47y+/a7m4hgfZgNeN0Wjt3P1UXt6k/IdCEtwuckT58zm1k2rwBzoj15/bGQcn7Ns+gLl+PLVaOxgxHvHXVf7FEkMia7zhe/uuIVy3LYJPf/eC6SuuQrGEU/MJ3KBeHb1mzzCA1qV89nzwD3iVL0AnqB+nSOZk+L0u+DyunlD+/DWcnI0DUDZ8efA3Uv7z6hd0W9SO8q8c5fj98yt4aXqjZnFWM1QE/3Bt2yed25zR43YRhkOSIxu+M+tKJsxELKANuUl2wGfk+OwGxiI+jNl4vwAgprZQWM9YCP4NlD+gNH6rdcXG4XtsRsqfiPDB1+/G2YUkvmsyVfPsQgJ5uaRZY/vGIxgOSfhei3x/W8GfiN5DRCeIqEREh6ru+xgRnSOiM0R0t+72GBF9iYhOE9EpIrrTzhoaEWzRuL52ksjJCPu8iAa8PeH5J9XXwIP/mi74G/VLmV3PYDDotZUayef4ckuQX16nLWbI8M+YX3JjLOpDMidvuuJUlP/mDOuxqM+RFg+8lfNkLKA9Tydk/JyYidv2+4FyVe1GuvnPvVFfn1qMR/1YNGjNARj38tfzzpu2YyTsw6f/42LTawTKV0dc+btchDv2DON751Zasm9jV/kfB/BuAE/pbySi/QAeAHAAwD0APklE/Fv65wAeZYxdB+AmAC1tth/oRc8/KyPi9yDi9yDeAarOLlz5n1CD/0oqr9k9AcmNgNe9SfkrOf726huqbR8e/K1WTWd1yt9oEzddw/MH1BYPDnj+M+tZDIckBCS3Nueg3bZPJl/Ey4sJHJyw5/cDQFRt4rdhIsWZK//hJuYGjEd9SOeLhn+zDYPWDnp8Hjd+9s6r8Z2zS3h5IdH0Oo/NbCDs82DncLnG4LV7RhCQ3FqjPiexFfwZY6cYY2dq3HUfgC8wxnKMsYsAzgG4jYgGALwBwN+qv59njK3bWUMjAj2Y7ZPMyQj7PIj6vT3h+fMv2sm5OBhjWE3lNbsHqN15cXY9g4mYPQuheo4v98utCoVMRfCv3ao5ldvs+QNQN4idCP5Kjj9QbnjX7nTPU/NxlBhwwAHl73G7EPF5TNk+y8kcBgJe+DyNrxLHVVtqweC9KDd1q18f+1N3XA2fx4W/e7p59X9sJo4DE9GKYtQHXr0D3/61N5ouhmuGVnn+kwCu6H6eVm/bBWAJwGeI6AUi+jQRGZbSEdGHiOgwER1eWrLW5KhXN3zDPkX594rnH5Tc2MgUcH4phXS+WPFhHwpJm0bjzcez2GYj0weo9PwLxZJmu1j9rHCBEZBc5QldVVZOWje8Xc9oROlZYzU/nDOzlsZkdfBv82f/BN/sdSD4A4rfbmZfxijHvxblK7baFpzWyz9Yv6XKUEjCj946hS8/P9NU0VehWMKpubhm+XBa2ZWgYfAnoseI6HiNf/dZeD4PgFsAfIoxdjOAFICPGj2YMfYgY+wQY+zQ6Oiohacrq7tMobXtUbeSRE5G2K8q/y73/EslpT31rVcPAgC++7Jykh+uo/wz+SLW0wXbtk+5BkTGQjwLHneteuRc+fsNbB/GmOL5+2oo/6hSzGanOpQxhtn1rKb8O8X2OT4Tx1BIspWWqycWNHfFa9TaoRa8Q+yCwf5LM7YP5/2v2Ym8XMIXfnC54WMvr6aRl0u4frt9a6xZGgZ/xthdjLGDNf49VOfXZgDs0P08pd42DWCaMfasevuXoJwMWoZfLeRxunVvO0lkC4j4PIgGul/580lTr945BCJoGRKblL8uKGo5/rZtn/J+ELd8lJ/te/6DQS+8bqrw8XNyCYyhtvJ3YJzjRqaATKGo/V34Sabdts/x2Q0cmIg2Pa6xEQMBL9ZNbvg2rfybtn0aB/9rxyN4zZ5hfO77lyA3SB/mGVnNnFScolW2z8MAHiAiHxHtAnANgOcYY/MArhDRPvVxPwzgZIvWAEBJveq1UY5JVflHesDz5x/68agPu0ZCWi+TesFfq+6N2tzw1WX7zG3oBqBY9fw128cNIlLSPXVBRJs5bKD8AePZv83AhQAPTDzbJ9nGbJ+cXMTZhYRjlg+gBMhW2T5hnwdhn8cw138jU4DHRZpwaMTPvmYnZjeyeOzUQt3HaRPeHGjs1yx2Uz3vJ6JpAHcCeISIvgkAjLETAL4IJbA/CuDDjDH+CfwFAP9IREcBvArA79tZQzMEWzCou10wxjTPP+r3ICeXkOvipnU8YIV9XhyYGNAsiurgn9b1c+FZOXaVv8tF8HtdyBaKWg98QOm/YwX9hi8AjFZN6OJfcH6/ntGw8lqsjCjk8Apjn3q161KDVDuV//fOr6BQZLj1qkHHjhkLNh/8UzkZ6Xxx0xCXeii5/rWVf1zt69PsVcxd149jMhbAZ7/3St3HZQp8zkOXBH/G2FcZY1OMMR9jbJwxdrfuvo8zxvYwxvYxxr6hu/1F1ce/kTH2LsZY7X69DhJowaDudpGTS5BLTFP+QHe3eOBN6iJ+D/br/M7hUPnLWj24e07r62PfQ+ZXhbPrGS2Dw7Ly13n+gNKtU2/j8I3XWmMnh8L8NVq3ffjJUZ/V0u7mbg+/OIuo34PXXzvi2DGjAS/Wmwz+yyZy/DljEV9d5W/GmnG7CD9959V45sIqTs/HDR/HhYHVkaRW6PkKX0BV/g4F/9n1TFu/TDzQc89ff1s3wusUwn6P1hfF46KKYRmDwc3BfyQsNZW614ig5FFsn/UspgaDymfF4vubzRdBBPjUds3Vzd34RnKtS/uQpEyGsjKikMOVP9/nAhQbo10bvum8jG+emMfbb9zuyHvFGQh4kZdLTXX2NFPdy+GFXrXYyBQQMenL/8ShHfB5XPj7710yfEy9q8JW0RfBP+B1zvZ5z19/H594/GVHjmUF/kUO+z2I+JQPYTf7/knNpy4r/8GQVHFZPRyuDv4ZR1Q/oF4VqrbPRMyPoOSxpfwDXre29tGIMiKQ9wpK11H+RISRkL35r7mayr99ts+3Ti4gnS/i3psmHT1uLKB8Hpqxfsz09eGMR5X+PrWqauN1+voYMRiS8MZ9o3j2gnGPnky3ef7dQkByZlB3oVjCzHoGFwzGCm4FSZ1HzvuLdLPy13v+oxEfxiI+raUDhyt/Psh9bt1+dS9HuSqU1aIxZQCK5Tx/NfhzuM/MT1r1lD+gWD9WBpVwain/kORpW3uHh1+cxfYBP27fNeTocXnwbSbjx0xrB85YxIecXKo5KClu0vbhTMaCdRvGlTd8he3jKPzS3i68xUC9xk+tJqF65LzIC+jugS7c8w+rr+WtB7fh9t2VwWJEVf7fOrmAvFzC7EbGsZxxv9eN5WQe8ayMiVhAUf6We/uUNL9fWXdl+qam/A2+4MO6YeJWqOX5R/ztsX1WU3l85+wS7r1pwvFCJa2/T5PK30UwVSGrVflWZV6VSgzLiRwGGxR41T6mD6l80fC7msnLIKo8cbeanp/hC6jK3wHbh2diGOUAbwVc+Uf8Hk35d3OhVyKrfOh5y4P/ed/BTY+JBSV8+E178FffPo8rq2kksrKtIS56gpJba6i1fcCPkGRd+WcLxYovb3Wffk3d1Uj1BJTCtnM25r/WVP7qQJet5pFjc5BLDPe+asLxY8eCzQf/5WQOQyEf3CZOQOUWD1lcOx7Rbr+wnEQiJ2+qwjV3zJyWqKEnna+0DLeC/lD+XrcjvX24KltK5myX4VtF8/wrlH932z5hn6fhh/7X774On/ypW7TgaDfNk6NPBpiMBRD02fT8dZYO95mXm1X+YXvzXzXl721/ts/DL87gmrFwRQaXU5Rtn8Z/KzM5/hytyrdK5B25pCQm8mp0c8es3zYiXShuqd8P9EnwDziU7bOipuEVS8yWN2sH/YZvWPKAqLs3fBNZualqSQB42w3b8dB/ey3ee9tVeMM11tp9VMPnPQDKYJiQjWyfTL7K848oVgO/YuR2klFGx1DIh0yhaPnKQ1P+nvZm+8jFEp6/vI679o+3RMlGTdg+cxtZ08Gft+ao9uiPXFrDYNCLXSOG7cgM4SeUeYPgn8lvnvPQavom+Duh/PUFOO2yfsobpB64XISwr7vbOidzBa0HTTPsHYvgD959Q0XXTzsEJLUgioDxiM/W/lCmUKzw/IOSB0HJreWap/MyAl63oQduZUqVHl7sV6H8JQ+yhVLD9gJOspBQrox3DAZbcvyIzwNXE6LnyKU1nJiNm95wDkhuRP2eTSr9yKU13Hr1oKUTWqNuoem8jKB3a134vgj+Qa8H+aL9L4C+AKfRkOdWkczJ8LpJyyXv9uZuCXU2Qbvg2RXbon543C4lNdKG51+t6kfCPi34p/LFmq0dOEYjK5t//s3KX+vvs4VFjnMOVWAb4XJRw0Ivxhj+8NHTGAn78P7X7DT9HNW5/uvpPM4vpXCzxUrlkM+DSJ22EWmh/FtD9bg+q6wk8/Coqs2o61+rSVZ55N3e1pn3KWoXPFjzWcBByWN9kldh8xd4VFflm87JdVP5hrXUUGtXlTm5CLeL4HFX2j7A1jZ3m1UrsCdszFduRKP+Pt85u4TnLq7iIz+811LVLM/157xweR2ANb+fMxY1rhzO5IXn3xKqJzZZZTmZx66REFwELGy0T/nrg2W3D3RRlP/WdTKshn/htAEokhv5Ygl52fxVYrXnDyhpqnrlX+8LzpW/1f4+2UJJuyLktGOgC1f+2x1Kx61FrE7wL5UY/s83z2DHUAAPvPoqS8cfi/pwaSWtFegdubQGt4tw01TM6pI3nVD0pEXwbw3Vs1qtsprKYSzqw0jY11bPn1f2Auj6ts4826ddBLTgrwQqPmLRilCo9vwBbvsowTydl+uq0OpKZrPk5M3P346e/rPrGXXMaOtO6tE6bZ0fOTaHE7Nx/MpbroXksRbi3n7Ddqyk8vjnHygzqY5cWsOBiagta2Zb1G8YN5SrRuH5O46+b7sdlNmyPuUM3i7bJ1eoUP6Rrvf8Cw1H4rUSLgwmBsrKH7A2/Spbw/YZCfuwllZaPDRSd0HJA7/XZTmTrL7y3zrPf3Yjq/09W8VAwPiK96EXZ7BjKGCrrcSbrxvDoasH8eePv4xEtoAXr6zjFpudScfULq+lGmniyoavUP6Oo9k+BXvqZyWZx3BYUi/f2pfqGfHpbZ/uVf55uYScXGqr8ucePLd9uPI3m25ZKJZQKLJNts9oxAfGFDWfzhUNc/w5wyGf5Q3fnFzapPz5hu9WKv+5jQy2t2izl1OvrfP0Wgb7xqOmCruqISL8xluvw1Iih49++RgyhaItvx9Q0j0LRaa1KdEjNnxbhDbKMW892ydbKCKZkzEckjBeZ+Om1SSz8ibln8gWajah6nR4QGpnts+ukRB8Hheu26ZUcmrK36RSzhZq5/DrWzyk8nJDX3c4LFlO9cwWipuUf1s2fHWjJFvFgJrtU+tzP7OWwaQDJ59X7xzCm68bwyPH5gDY2+wFFNsH2JzuyRgTG76touz5W/8CcB92OKzYPqupfFuGqCRzlR55xO9BiW1tKp9TaE3q2rjhu38iitP/6x7sGFJy0rlQMGv7aL38N2X78E3cnGL71En1BJRNX+uef6kixx9wboi7XCzh8Curm25//vIa/k0NjoByAlpN5R3rvWRELCChWGKbPvfxbAGJnIzJQWdOPr9+9z4QKYHb7gltLFq7eCxfVGZ0iODfAgIOpHpyNcaVP2Bv3qpVElXKX+vv04UZP3yvop3KH0BF0Q63Scyme2bVq0oj5b+czCOVkxvaPkMhnw3P31j527V9nji9iB/76+/jwlJl76G/fvI8Pvrlo5oC54N2nOq6aoRRi4eZNSXTaDLmTIHZ9duj+Mibr8F/et1O28cqt42oDP6ZNnT0BPok+Dux4ctbO3DPH9j6Kl/ukUeqlD/Qnf19NNunjZ5/NXaVv1HwX4hnkZNLDb/gI2Glp78VG6+W5+/zuOB2kXaVZRWeWaMfdA8oVzTxrIxpNehqaZ4t9vyNWjzw4O9kgdkvv+VafOgNe2wfp9w2ojJutGN+LyCCf9OUlb+vouvfVpLSNXXj8L443Zjxo00la6PtU42m/E1+VrTgL23OtglKblxaSVUc34ihkIScXLJk4+VqKH8iQsiBOb789S1XXZXwNNaTc8qIQj4LebLFnr9RZ8/ZDfX5HbJ9nETyuDAckjb199GmeIng7zz8j9rM2Dcjaiv/rQ3+iRoeeSf19P+Vf34Rf/lE81POqnv5dwKa8jcZLPmle7XyBhT1f3k1XXF8I7QqXwubvrWUP8Cbu9nbEzIK/tyiOjGrBH8n5yvXQ+vpn96s/CWPCyMhc83ctoqxqH9TzyBh+7QQye2Ci+xt+K6k8pDcLoR9HgwGvZDcri23ffSDXDhlz7+9ts/hV1bxlRdm8N1zy03/jr5JXadg9SrRKNsHUKycyytK8G+k/LUqXwstHmopf+U57bd15gFKX32cyRe1K5STs8pMhLmNjGPzlethNNBlZl0Z9OP0ABmnGI/6NtUI8bgkbJ8WQES2p3nxHH8iAhFhLOrb8ole+kEunE5R/p944hyA5kbrcRI1Xk+78bpdkDwu655/jS/wSNiHOfWz0lj5q1W+FpR/Vi7VnATlxECXbA3lz//f6yZN+c9sQZonYGz7zKxnOtLy4WyL+jG/UeX51/nstJK+CP6A/bbOK8mc9sUElD4dRr25W0WyruffPuX/4pV1PHV2CX6vq2YBixGJbGWH0k5B6elv0vPP11H+aqEX0FjdDWmdPa0qfyPbx3nPn///oauHMLeRxWoqj7n1TEt7+nACXje8btrU2XNmLdPy6mI7jEX9WEnltJ5BQHuGtwN9FPyDNkc5rqqtHTjtKPTSD3Lh+L1uSG5XW1M9/+LxlxELevGeW3dgLd18wVkyV0DE793S0XXNEJTMK2WjbB+gPNFLOXYj20d5rJUq36y8ub0DoFhNztk++uCvrPEN1yqDdU7MbmB2PdPyNE9AuZqv7uyZk4tYTOQ6WvmPRxUhoP87atk+op9/awh47U3zWk7mNT8WUNK2Frfa88/WTo3cORLE2YWE6eM9enweX3l+2taajs9s4PHTi/jg63ZhcjCAvFxq+u/c7qZuRoR85pV/1qDIC1CUf/nY9V9vQHIjKLlNV/nKxRKKJVZzw1fx/B3a8E2U18UD2BuuHQEAPHNhBal8sWV9/KupDv7z6mZzqzON7MCrfOd1XYEzqtAQtk+LsG37pDbbPomcvKVl87WUP6CUnR+5tFazYVQ9PvH4y/jdh07YyoL6zNOvIOL34GdesxODqg/brPWTbPMgFyMsKf86ts+o7nPTzKW9lVm+WbUFdS3lH3HA9uGfkZVUTruy47OJ94yGMRkL4LGTiwBa28dfz0DAW5HtUy7w6tzgX6tGqGvz/InoPUR0gohKRHSo6r6PEdE5IjpDRHfrbv9l9XeOE9HniajlUkEZ1G3tC5DOy8gWSloaHgBsG6hdrddKklkZLtocYG65ahDxrIzzVdWX9ZCLJZxbTCKRk/HkmSXLazpyaRWv2TOMqN+LWFAJcs1u+na08reQ5+9xEbzuzV+pEd3nplGFL6BU+VanVDYix688DJW/bKv/E1f+hSLTMstWUnlE/B74vW7sn4jijHr1uRW2D7BZ+Ws1Bh1s+4ypVb6LuoyfdB3h0EqcUP7HAbwbwFP6G4loP4AHABwAcA+ATxKRm4gmAXwEwCHG2EEAbvVxLSXgtZ7twy/Bh3S2z7hBtV4r4X19qj1y3nDqyKW1po91cTmFvLrp9K8vzVpaz0a6gFdW0rhRHXAxqAb/ZpV/ItfeQS5GBCXzqZGZGiMcOfoB4o16+wDW+vvUU/4hnwdyiWkD3q2gv2peUk9MS8mctp+xf3tUu3+rbJ9YUNoU/IlaX2Ngh5GQD24XVdo+hSL8XteWp6faDv6MsVOMsTM17roPwBcYYznG2EUA5wDcpt7nARAgIg+AIABr0ccEQclt2d7gKmxEd/nOmzRdXk3ZX5yJddQKlrtGQhgMek0F/9Pzikp79c5BPH56wZItcHRmHQC06UZl26dZ5V/oSNsnJJlX/tlCsabfD5SVv8dFkGpcGVQzHDLf2bOe8neis2emUNI6nvLvw3KibIUemFCCv9tFWhuDVjMQ8Fb09plZy2A07Gt5jYEdXC7CWMRXkSmYztcf79mytbTw2JMAruh+ngYwyRibAfBHAC4DmAOwwRj791oHIKIPEdFhIjq8tGTdmgDsbfhqHT112T5TgwFsH/Djt752HP/nm6dtj4hsRE4u4qmzS7h919Cm+4hI8f0vmwn+cbhdhF++61pkCyU8dnLB9JqOTiuFPTdMDQCAzvZp0vPPdajn7/OYtghrjXDkhHweBLzKRm4zmU1Dqudvxqbhw9trKf+YyZNy7eMXtc6nPPivpPLaie3ApPIZ2Bb12+qjb4ZowItETtb2umY3OjvHnzMa8VWc3NN1PjutpKngT0SPqf589b/7zD4hEQ1CuSrYBWACQIiI3lfrsYyxBxljhxhjh0ZHR80+VQV2Nnxr2T5+rxtf/4XX4d6bJvFX3z6Pu//sqZZ2+fyPs8uIZ2W881UTNe+/5epBXFhKNW0XnJlPYM9oCHfsHsbEgB8PW7B+Xrqyjt0jIa3aUgsyqcZBhjHWuZ6/5DadHVPP9gGAkYjUtLobCfmQL5aQMKHUeXtxo/YSACx3CwWUk9vUoBr81c/5cjKnHXtiwI9Y0LslOf6cWMALxspZcEof/84P/sMhqWJPpx29/IEmgz9j7C7G2MEa/x6q82szAHbofp5Sb7sLwEXG2BJjrADgKwBeY/UFNEtQciNdKFra9FrW9fXRMxz24Y9//CY8+NO34vJqGk+dtXd1Uo9/PTqLWNCL1+0dqXn/reqIuReaVP+n5hLYty0Kl4vwjpsm8NTZJayZ9Jlfml7HjarqB5Tq2Ijf05Tnny0oqYmd6vlnCkUUTWRPZQolQ9sHUAJwM34/oCv0MmH95Op4/vxza3VCGKCc3CZifrhISXsuFEtYTxe0YxMR/vPrd+PHbp2y/Bxm4c99fHYDpRLD7Hq2K4L/SHiz8u/Y4G+RhwE8QEQ+ItoF4BoAz0Gxe+4goiAp18A/DOBUC9cBQAn+xRLTNjnNsJrMIyi5DZXbm68bg+R2adkOTpPJF/Gtkwt468HtNbNJAODGqRg8LmrK909kC5hZz2jTq+69aQJyieHRE/NNr2khnsVCPKdt9nIGg1JTtg9vR9FJTd04vP+OmaLAbL6IQI3WCpybpmLYNx5p6lhDYXMb50A5FbN6mAugKxyzqfxDPo8ybyCV064w9ZlMH37TXjxw21WWn8Msb9k/jslYAL/78AnMbmSQL5a6wvYZDvsqUmYV5d+Fnj8R3U9E0wDuBPAIEX0TABhjJwB8EcBJAI8C+DBjrMgYexbAlwA8D+CYuoYH7a6jEQH1j5u1MMpxJZXfpPr1eNwu7BkL48x8a4L/E6cXkc4X8c6bths+JiC5cWAi2lTw5wVhPPgfmIhiajCAJ88sNr2ml66sAwBu2jFQcftg0NuUt8wtjXYObzeCfxHTJmyXRrbP/7j3AD71vlubOlbMoGNlPeop/8GgF0SVTdnMIBdLyBdLCHjdGAlLWErkNYtTH/y3mqDkwe/dfxDnFpP4nYdOAOjsHH/OSFiqSJlNFxqP92wFTmT7fJUxNsUY8zHGxhljd+vu+zhjbA9jbB9j7Bu623+XMXadah39NGOs5fmS2ihHC0Pcl5M5DDVoEXvdtkjLgv+/vjSL0YgPt+8arvu4W64exEvT6xV9Q2pxak5Z5z41+BMRbpwa0G5vhqPTG3C7CPu3Vwb/WFBqSrF2YkdPDlf+ZnrqZwrODeDWNs4z5pV/Lc/f43ZhMChZ6hcElNNIA143RiNKDUKtDLh28KZ9Y7j3pgk8cXprC8zsoE13U9+PdgxvB/qowtfOQJeNTEFTY0ZcOx7BfDxrSq01QzxbwBNnFvH2G7Y3zKK49epBZAslnFIHaxhxZj6BiM9ToZL2b4/i8mq66e6gL02vY994ZNOHVlH+jYNWsgMHuXCs9PTP5Is1A68VyiMKnVH+gLKPYHUwvDarQHJjJKwEf36sdip/zm+/Y7/2N+sO20dt261ePaVzvef5dxTaHF8Lwb+ZNgTcQnHa93/s5ALycgn3GmT56OH59sdn6gf/0/Nx7NsWqUg7vF4t0mnm6oUxhqPTG5ssH0BRretNZPtonn8nKn9u+9T5rGTyRXzgsz/AD9Sh5tkGto8ZuBVW3a64HjnN86/9lbZSO8DRzyrgmSqa8o+0P/iPRnz4wx+9EfffPKl1ue1kqpv39WKef0dhR/nHs40rUfe1KPg/d3EVsaAXN++INXwsV2HVdkEiW8BjJxfAGANjDKfnE9p6OfvVIp2TDa4aAODSShobmcKmzV5A2fBN5OSG1hP3/Dszz5/bPsbK/1+OXMHjpxfxN9+5AKCx528Gj5o1ZUX5G119jIR9lgbEAJUdS0ciPmQLJVxaTcPncWmFX+3mnoPb8Kc/8ap2L6MpRiI8m0t5P5y0DM3QN8GffzGttHVWWg/XD1LbB/yI+D04M984eJrh6PQGbpgcaKo4yO91weOiTcPcH3pxFh/8h8P4nYdOYGY9g0RWxnW6cnxAKc6JBb0NLSNAsXwAVKR5cgZDzVkWHe35axu+tT8rcrGET//HRQDAk2cWsZzMOf4FjgW9ppS/lu1jYPsMh+3bPgHJpQmM03NxjIR9HdeOuxsYCkogApbUlNlCkSHYqUVevUDZ9jG34VsolpAtlDa1Ua6GiLBvPIKz8803V2tEtlDE2YUEbpjcHGSN1hDxezb59jx///8+cwk//7nnAZRtKv3v7t8excnZxsH/yTNLiPg8uLZG6mKzVb7JbO0OpZ0Av0o0Uv6PnpjH5dU0fuUt10IuMXzpyDQYM1bdVogFmkuZ5eTkEohg2D5iOOTDRqaAvIX+PhndZjLf4D27kOwIy6cb0Tbgk7m2DW8H+ij4B5vwcWthJkhduy2C0/NxW90T9ZyeT0AusZoK24iI37tJ+cezBfi9LvzCm/fi2IzSkqHa9gEU3//0fAJyHctmLZXHI8fmcP8tkzVrDprt75PIFtRpTJ33EeQ992ulejLG8DffuYDdIyF8+E17cXAyin969jIAZ7syxoLeTVOq6pFV5/caKfFhC7UDnArbR1X+yZxc0apaYA6+d9Ku4e1AXwV/a55/wkRWynXbIohnZcc6fR5T7ZUbanjrRijKvzJoJbIyBgJe/OqP7MPH3nod7nvVRM2Nsf3bo8jJJbyyYtys7svPTyMvl/CTt9cu5mm2s2cyJ3ek6gf0yn/zZ+X7F1ZwbGYDH3z9brhdhB+9ZQqXV5Xh7E6qt+pe9Y3IyaW6Vx5csVuxfrI6darvUDrcIP1ZYAy34do1vB3oo+BvNdsnkWs+K4XbIKcd8v2PTm9gOCRhwkS/lFq2Tzxb0IL9z/3QHvz5AzfX/F2e8XPSIN+fMYZ/evYybr16ENdti9Z8zGCoOdsn0aGDXADFN3e7qGZztwefuoCRsIR33zIJQKmO9qgpuJ2g/I3gsyis5Prrlb++vxXfuBSYZyTsw0oqL2yfrcDqhi9X0c1UovLyfSsjFWtxbGYDB5vc7OVE/V6tcpATzzQXaPeOheF1k+Gm7/cvrODCcgo/ZaD6ARO2T4f28geU/Y9gjeZuiWwBT51dwo8f2qGp7OGwD2/cNwagNZ5/s9PZGin/YQv9gjj64O91u7T3uBNy/LuVkbAPy4mc9rcVyr+FeN0uDAS8pidvmfH8B0MSxiI+rVe+HTL5Il5eTJry+wHu+ddQ/g2K1ABA8riwdyxiuOn7j89exkDAi7fdUKfNhNcNyeNq2CQukS003ERvJyHJs+kq8fClNZQYNjXXe88hpZkZ72rqBLGgFyUGJJtMUMgVag9v53Dlb3ZCGFBZ5AWUg/6wCP6WGQkrKdE8K04E/xazZzS0adRhqcTwvfPLhr/DbZ9mVeq+bRFHlP/JuTiKJdZ0pg+nlucfzxSaLn7Zvz1aU/kvJXL49xPz+LFbp+oqTCJqqsq3U+f3coI+96Zsn2curMDrJtysdlDl/Mj+cXzhQ3fgtp2bZy1YZcBkf5+sXL/COOr3wOsmS5099UVeQHnzuN2tHboZfuK8wveLvGLDt6XsHQvj3GLlZua/n1zAT/5/zxr69EmT+ej7xiN4eSFpqh1wLY5pufQxU78X9XuQzMsVdkEiKyMaaG7912+PYDGR26QQv3RkGoUiw3ub6No4GJSayPbpzF7+nJC0eeznMxdW8aodsU3+LBHhjt3Djo7hMzsPuZHyJyK1xYM1z18/n5gr/1Gh/C3Dbbgra0rwF8q/xewdC2M5matQU8fUUYRGA0jiWXOVqHvHwsjJJcxtZGyt9dhMHKMRH8aj5r5gEb8y4ILbBYyxig3fRvBZrHr1XyoxfOEHl3H7riHsHQs3PEYs6G2c59/Bnj8A1fMvK/9kTsbxmQ3csbt+cz2n4BZSs83dGil/QMnOseT550sVm9nC9rEPr5Hgyl8E/xazZ1QJXOeWyrYM72SZMej2mczJ8LqprqrSwxWbmerMWhybWW+6slcPV/jc+skWlArCZgMtz/j57rmyFfb9Cyu4tJI2TO+sppHyL5ZYR6d6Akquv175H35lFcUSa9hZ1Sm0ts5Nfo4aKX9AsWuWLdg+mar5xLdePYgDE9GGzQ4FxoyEePBXRKLI9mkxXLWeWyz7/lzhGuX/K0PGvU0HYR58qzNuzJDKyTi3mDTt9wPlvQm+6RtX/9us7TMYknDvTRP4zNOvaKrkn569jFjQi7sPbGvqGLEGA124l96Jvfw5QanS83/mwiq8bsItV8e25PkHguY6e2blYsPB5coEKfO2T3XTunfeNIFHPvJ6R22ufoPvm1zWlL/w/FvK1GAQkseF80uK77+ezmNuQ8n+MQr+SZPeNLdX7Cj/k3NxlFjt3jmN4PYUP/nE1XWY6Xb4/7ztenhchP/19ZNYSuTwzRPz+NFb6m/06hkMerGeLhhWOndyXx/OUEjC7HoGM+uKMnv24gpunIpt2Zd0wIryrzNJDLDe2bPecHqBNUI+DwJeNzJqfcZWDb3X01fB3+0i7B4Jacpf38HSqPjLbDES/9LGm+yLX4uLy8rJ6Zqx5sb+6dms/FWVbeISfduAH//tzXvx7ycX8OtfeglyieG9t+1o/IsqQyEJcokZDiDv5F7+nA+8bhfcRPjVL76IRLaAo9MbuGO3c9k8jfB53Ah43U3398k1ofyHwz5kCsWaxWv1qLZ9BM7A1X87/H6gz4I/wDN+lOCvn1xlaPvkTCp/HvxtKP8F9WpkzORmL1BW/lxd85OQ2bTKD7xuF3aNhPDkmSXctnMIe02ciLRMFYNN9E6e38u5ejiE3733AJ65sIpf+PwLKJbYlm32cmLqFVQz5Aol+Bspf4stHpR21X0XKloO3zhvh+UD9Gnwv7KWRrZQxKm5OIZDSntVo26fiSZ6+euJ+Dwgshf85+NZDAa9lipGo9XK34LtAyjK83feuR8A8L47rzb1u7wCdNVAtXZyL38977l1Cvcc2IYnzyzB4yLcevVg419ykIFA8y0emvP81QlSqu9/finZ1PAeJwfVCMrw96Mdm71AHwb/PaNhMAZcWErh9Hwc+yeiCHjdxp5/E7389bhchLDPo9ktVliI5zAebb6fjx7N89eUP7d9zAfaN+0bw3d/4014543GFb21iDVo7qY1y+tgzx9QcuP/4N03YCziw81XbZ3fz4kFm2vuViwxFIqssfLnE6SSeTDG8POfO4KPfuVow+Nn2jRjttfh70e7bJ/O/va1AJ7xc3YhgbMLSbz/NTtxai6OtEHPHysNyAYCXnu2TzxrOfj7vW5IblfZ9rGo/DlTg0HTvzOoZarUDv7d4PlzBkMSvvbh18LVhqElsYCEC8uN50PkZD7IpZHnr9o+qRyOzWzg7EISu0dCDY+fKTg3n1hQhjfGa9dVVd8F/10jIbgI+JY6G/f67coQ8lobvowx09k+gNpczcaG73w8qxVbWSHi92jPn8jKkDyuLf3yam2du9jz1zMRa89Q8GY9/1yBj3BsUvmn8vjykWkAaOoKVdg+raHdyr/vbB+/140dQ0E8dmoBgFLUFPR6amZA5OQS5FLzBVKcaMBjOdWzUCxhOZnDuIk2ztXo+/so1b1bG2SjAS+I6ij/nAwidMz8105lQG3r3Gg4EJ/f20j5ByQ3gpIb8xtZPPzSLADF1myESPVsDbzKV2z4biF7R5UWDJLbhT2jYQSk2p5/3KJCVWwfa57/cjIHxpSZulbRd/Y009TNKdwuQtRvPIOW9/UR81/rEwtIyMvKGNF6ZLUxi42/zsNhCV8/Ooe1dAE3XxVTK8CNj88Ya9uA8V5nJCQ2fLcc7vsr/etdCBrYPkkTvfz12LF95tU0z20D1vumRAN65S8j0oYyfP0aqklk5S0/IXUjzfb3aVb5A4rVsJrKYzTiw9sOKhv5KYN6DH7sEmtfgOplhsPC9tly9qjB/7rtSu560ED5W61EjQaMVW8j+LyBsYgN5e+rVv5bf1kZ8RmfABPZQkdX93YKzfb3MaP8eXrhu141obWQMDpJ648tbB/n6epUTyJ6DxGdIKISER3S3T5MRN8moiQR/WXV79xKRMeI6BwRfYLacO3PG7zxTdWAVNvzT+asZaUMBLxI54t1L6eNKCt/Zzz/RJODXJwmGvAYWl9KR08R/BvRbH8fs8ofAN59y5SWapuso/wzIvi3jFhQwraoH7uGG2dctQK738DjAN4N4G+qbs8C+G0AB9V/ej4F4D8DeBbAvwG4B8A3bK7DFDdODeDnfmg37r1pAgAQNMjz17JSTGf7lKts9TNPm2E+noPXTRgKWh+UEfGXU03jWbktyj/q92pNq6pJZGUt7VBgTCzQXE9/rs4b9fYBgHtfNYFY0Ivrt0e1Yq+6wb+NM2Z7HbeL8PRH34x29cezFRUYY6cAbNq4Y4ylAHyXiPbqbyei7QCijLFn1J//AcC7sMXB3+t24WNvvV772SjVM2Gylz9H3+LBbPBfjGcxFvHb6pgY8XuQyhdRLLG2bPgCyt/AyE5I5mTsbCK/vN/hnv9Gk56/vwnl/9q9I3itOoaSi5pkHdsno1lKIvi3gnY0dONstec/CWBa9/O0eltNiOhDRHSYiA4vLS21bFFByY10obgppc5q8DfbkVHPfDxry/IByieflVQOObnUFtsn4vcYFroJz785Yk3aPmaUvx6tD1Qd5S88/96l4aeFiB4jouM1/t3X6sUxxh5kjB1ijB0aHR1t2fOEfB4USwz5Ko+eXw5b2fAFrHX2nI9nTU/vqoZ/qWfXlf2Ddtk+iZxcc5xlok1WVLcR8LrhdVPD/j5mlL+esE/5nNZV/nnl2ML26T0afgMZY3c5+HwzAKZ0P0+pt7UVrmoy+crmWIlsAQGvGx63OUXFbRYruf4LG1n80LX2TnQ8sM6sKb3o29FGgZ8Ak1lZ27gEgLxcQk4uCeXfBESEgYDUMuXP61fqFXqJDd/eZUttH8bYHIA4Ed2hZvn8DICHtnINteB5ttWbvlazUqzaPsmcjFS+aKvACygH+5l1ZcPVSlM3u0S1BnOVf4Nkl3T07BRiQa+jnr+eoNcNIuH59yt2Uz3vJ6JpAHcCeISIvqm77xUAfwLg/UQ0TUT71bv+K4BPAzgH4Dy2eLO3FgGD4B/PWpszq41yNGn7OJHmCZQD67Sq/Nux4ctPQNV/g3JfH1Hk1QyxQOP+PlaVv8tFCEue+p6/yPbpWexm+3wVwFcN7ttpcPthbE7/bCu8t0Z1xk/SZC9/TsDrhsdFpjt78gIvqx09OTzYc9unXXn+wGbry+omer8SC3q1vRsjynn+5rVc2O9pSvkL26f36MsK32rKtk91oCpY6jmveLXmq3y58rcb/Hlg5fNn25Lqaaj8u6OXf6cwEJAafo5ychGSx2WpV1LY59mU57+RLmgb9SL49y4i+ENn+xSc8fwBRW2bHegyryp/5zx/vuG79YF2wGCcpdWq6X5FaevcwPMvlOC3oPoBVfnrgn9eLuH1/+8T+MdnLwEoXw1buaoQdDbiHUVZ+VfbPgkLvfw50Tp57kYsxrOI+j22/VXJ44LPowx0cbuoLY2jqmcJc7qtl3+7GY34kMoX8dmnL6JUI20WUIe3W1TmYV9lA76VVA7xrIwXLq8DUPYT/F6XraJDQWcigj+AoFcJRJuyfSx6/gBX/iZtHwcKvDh83VF/e1on85OmyPaxx3tffRXetG8U/+NfT+JnP/OcZg3qyTYxvN2ISJXy58Pdzy0qE8QyYpBLzyKCP8q2j36Ie6nEkMxby/YBrHX2nLcxu3fT86vrbsdmLwB43C5llrHBhq/I82+OgaAXf/f+V+P33nUQh19Zw8997simx+SaGN5uRNhXueG7mioH/1KJiUEuPYwI/qid55/Ky2DMenVs1G9+oMvCRta238/hPfzb2Tc/qhsnyUlkZUjurR0r2e0QEd53x9X4iVfvwMWlzTN97Sj/sM9bofx58M8UiphZzyjze0WaZ08igj/KmQz64G9XoUYDmwNfPYolhqWk88q/nfaKfqIYJ5EtCL/fIjyJoLplhi3lr9o+fD9hJVXeXD63mBTze3sYEfyhFLv4vS4trQ2wn5UyEPCqI/g2dwutxUoyh2KJ2Zrdq4cH/bYq/xo9/UUvf+vw4S7VJ9RsoWQ5G4en3KZUy3M1lQPfInp5MSE8/x5GBH+VYNVAF7tZKeX+Ps2p/ytqQdZkzKHgrzbtakdrB06tcZZ2Mqj6HZ4+W13xm5OLlm20cn8fHvzzGA75MBL24dxiUvH8he3Tk4jgrxLwupHObbZ97OT5A823eDiverl8yphdOkP5bw7+SgaVCP5WKM/0dU75V/f0X0nmMRyScM1YGC8vJpEplMT+TI8igr9K9RxfzfaxqFLLzd2a2/Q9v5SE5HZhajBo6fmq4SefdhZT6cdJcuLZgtZKWGCO8nAX55V/Qqf8h0ISrhkP49xCEpm8LGyfHkUEfxU+0IVTVv4W8/x5V8smbZ8LSynsHAk6NtlHU/7ttn0yhYohOcmc6OVvlbLtU1nx64Tnz5X/aiqPobCEvWNhJHIyZtezIvj3KCL4qwQlT0WeP/8y2MnzB8zZPk5ZPoC+yKu9G74lBqSqsqiE7WONAXWmb7XyV6pwrQVo/jnhV7orKcX22TumfBbzxZLw/HsUEfxVqm2fRLYAIiBk8YNv1NumFoViCZdX0g4H//YWeQGbN70ZY0jmrBfO9Tualajb8JWLJSSysnafWbQN36yMQrGEDXXu9DVjEe0xwvPvTUTwV6ke4p7IKVkpVlsj8ODbTJXvpZU05BLD7lHnhppfNRQEEbBjKODYMc1S3dM/U1CGyoumbtaQPC4EJXfFhu+qagGNhCVLx+QbvomcjDX1WMMhCSNhSdtjELZPbyKCv0q18t9IFyyrKQDwedzwe11Ndfa84HCmDwBcvz2KI7/1Fly3LerYMc3C9xv4/klStHawTfVwF96LZzhsbe6zPtuHV/cOh30gIlyjWj8BSYSJXkS8qyrVef7KIHV7OfcDAW9Tts/5pRQAOKr8AWAoZE0NOkW17RMXg1xsMxCs7O+vBX+L7zXv+prMFbCqHot/bvaq1o9Q/r2JCP4qAcldUeE7H7ffZ6dWkVMtzi8lMR719ZwdUr3pzQvnRPC3zkDAUzHTdyWVA2Bd+QPlgS7LqcoTCVf+wvPvTUTwVwl63SgUGQpFZSTewoZ95d9sZ8/zS0nsHnHO8ukUIlq6q6L4uVfdaye5rSQWkCpsn+WkPc8fUDZ9E1kZq0nlRMKV/zXj3PYRwb8XEcFfRT/EPZEtIJUvYtuAdTUF8IEu9T1/xhguLKWwZ8xZy6cTKA90UYLVuQVlb2P3SO+91q2iejzoSjIHj4tspfRGVOW/msqDCIgFleB/6OohvPe2q3D7rmHb6xZ0HuL6W0U/xD2ZU75cTnj+F5ZTdR+zkspjI1NwdLO3U6je9D41F8dYxGfLouh3YkFvZbaPWpFrZ9IWH+K+kspjMChphYYByY0/ePcNttcs6EyE8lfRD3Gf31Auf217/lWZGbU4v+h8pk8nwat8AeDkXBzXb29f9lEvMBCs7Ba7nMzbPpmGdcq/3UkCgq1DBH8Vve2jDVK32V75mvEINjIFnJqLGz6mVZk+nQJv7paXSzi/lBTB3ybVnT1XUjlbfj+gDHRJqMpfBP/+QQR/FW2Ie6GI+Q2lvbJd2+dtB7fB4yJ87cUZw8dcWErC73VhYqB9xVithDd3O7eYRKHIcP32SONfEhgSU1s8rKsZP7wLpx34HN/VlP1jCboHEfxVglXKPxb02k5xGw778EPXjuKhF2a1SUnV8EwfO55tJ8NtH371s18of1tonT258k/mhO0jsIQI/ioBL9/wVTx/p2bpvuvmSczHs3jm4krN+88vpbBnrDf9fqA8evDUXBySx4VdItPHFprtkykgky8ilS9i2K7t4/egWGJC+fcZtoI/Eb2HiE4QUYmIDuluHyaibxNRkoj+Und7kIgeIaLT6u/9bzvP7yR65b/gQHUv567rxxGS3HjohdlN92XyRVxZS/d06qOS7lrAqfk49o1H4HELvWEHfXM3XuA1ErKv/DlC+fcPdr+JxwG8G8BTVbdnAfw2gF+r8Tt/xBi7DsDNAF5LRG+1uQZH4ME/pdo+Tin/gOTGPQe349+OzW2a53t6Pg7GgP0TvWuFRNQq51NzCeH3O4B+oMtKVTsGq+grrodEGm7fYCv4M8ZOMcbO1Lg9xRj7LpSTgP72NGPs2+r/5wE8D2DKzhqcgmf7JLIFLCdzjg1SB4D7b55EIifjidOLFbefmFV88AM9HPyjAQ8KRcVSEJk+9gn7PHC7COuZvK61g91sn3LwF7ZP/9C2a3AiigF4J4DH6zzmQ0R0mIgOLy0ttXQ9vMjr8koajNnP8ddz555hjEV8+OoLlVk/J2bjGAh4MRnrzUwfoHKYjAj+9iEiDKj1I+XWDsL2EZinYfAnoseI6HiNf/dZfVIi8gD4PIBPMMYuGD2OMfYgY+wQY+zQ6Oio1adrCreL4PO4tIpcu60dqo/9IwfG8b1zy5DV3kEAcHJ2A/u3Ry3PDOgG9MNkrm9je+leIqa2eCi3c7a/4csRyr9/aBj8GWN3McYO1vj3kI3nfRDAy4yxP7NxDMcJSm5cVIO/Uxu+nNt3DSOVL+K4avXIxRJOzyd62vIByn7yZCyAgaBo6OYEUS345xDwurWrVqtEfOX3ZVAE/75hy20fIvo9AAMAfmmrn7sRQcmDpYQzrR2quX33EADgmQtKyuf5pRRycgkHJns7+HPbR2z2OkcsqNg+K6m8bdUPlJV/1O+BV2Rj9Q12Uz3vJ6JpAHcCeISIvqm77xUAfwLg/UQ0TUT7iWgKwG8C2A/geSJ6kYg+aGcNTsI3fSW3y3Hvcyzix57REJ5Vg/+J2Q0AwIGJAUefp9MYUKd5Cb/fOXhnz2UHCrwAIORTPvei4V5/Yet6kTH2VQBfNbhvp8GvdazBzdM9x6K+lvjwt+8exsMvzkIulnBiNg6fx9XTOf4AMDUYxOv2juDuA9vavZSeQRnlmEfY58F2B7LSfB43JI/zgkfQ2YhrPB18XJ3Tlg/njt3DSOZknJyL48TsBq7bHu35oie/143PffB2HJzs7SucrWQgKCGelbGUzDli+wBKT38R/PuL3o48JuHK38kcfz137FJ8/++fX8HJ2XjPb/YKWgOv8l1KOGP7AMAb943hdXtHHDmWoDsQw1x08KyJVin/sagfu0dC+MrzM4hnZRH8BZaI6dJnnUrN/OMfv8mR4wi6B6H8dfAN31YFf0Dx/c8sJAD0/mavoDXEdCmzdgu8BP2LCP46Wm37AMAdasqni4Drton0R4F5BvTK3yHPX9B/iOCvY0uUvzoMe89o2Pa8AEF/olf+wzY7egr6F+H56wh6W+v5A8poyIOTUdy8Y7BlzyHobQYCZbVvd4SjoH8RwV/H/okorhkL257d24gv/ZfXwN2jk7sErUdv+4h2DAKriOCv4y37x/GW/eMtfx5h9wjsIHlcCEpKYZZoxyCwigj+AkEXMhDwagkKAoEVRPAXCLqQgYC3YlaCQGAWEfwFgi7kF958DfxeYfkIrCOCv0DQhbz9xu3tXoKgyxHSQSAQCPoQEfwFAoGgDxHBXyAQCPoQEfwFAoGgDxHBXyAQCPoQEfwFAoGgDxHBXyAQCPoQEfwFAoGgDyHGWLvX0BREtATgksVfHwGw7OByOhHxGnuDXn+Nvf76gM57jVczxkarb+ya4G8HIjrMGDvU7nW0EvEae4Nef429/vqA7nmNwvYRCASCPkQEf4FAIOhD+iX4P9juBWwB4jX2Br3+Gnv99QFd8hr7wvMXCAQCQSX9ovwFAoFAoEMEf4FAIOhDejr4E9E9RHSGiM4R0UfbvR4nIKIdRPRtIjpJRCeI6BfV24eI6FtE9LL638F2r9UuROQmoheI6Ovqz7uI6Fn1/fxnIpLavUY7EFGMiL5ERKeJ6BQR3dlr7yMR/bL6OT1ORJ8nIn+3v49E9HdEtEhEx3W31XzfSOET6ms9SkS3tG/llfRs8CciN4C/AvBWAPsBvJeI9rd3VY4gA/hVxth+AHcA+LD6uj4K4HHG2DUAHld/7nZ+EcAp3c9/COBPGWN7AawB+EBbVuUcfw7gUcbYdQBugvJae+Z9JKJJAB8BcIgxdhCAG8AD6P738bMA7qm6zeh9eyuAa9R/HwLwqS1aY0N6NvgDuA3AOcbYBcZYHsAXANzX5jXZhjE2xxh7Xv3/BJSAMQnltf29+rC/B/CutizQIYhoCsDbAXxa/ZkAvBnAl9SHdPVrJKIBAG8A8LcAwBjLM8bW0WPvI5RRsQEi8gAIAphDl7+PjLGnAKxW3Wz0vt0H4B+YwjMAYkTUETM4ezn4TwK4ovt5Wr2tZyCinQBuBvAsgHHG2Jx61zyA8XatyyH+DMB/B1BSfx4GsM4Yk9Wfu/393AVgCcBnVGvr00QUQg+9j4yxGQB/BOAylKC/AeAIeut95Bi9bx0bh3o5+Pc0RBQG8GUAv8QYi+vvY0r+btfm8BLROwAsMsaOtHstLcQD4BYAn2KM3QwghSqLpwfex0EoyncXgAkAIWy2S3qObnnfejn4zwDYoft5Sr2t6yEiL5TA/4+Msa+oNy/wy0n1v4vtWp8DvBbAvUT0ChS77s1Q/PGYah8A3f9+TgOYZow9q/78JSgng156H+8CcJExtsQYKwD4CpT3tpfeR47R+9axcaiXg/8PAFyjZhZIUDaaHm7zmmyjet9/C+AUY+xPdHc9DOBn1f//WQAPbfXanIIx9jHG2BRjbCeU9+0JxthPAfg2gB9TH9btr3EewBUi2qfe9MMATqKH3kcods8dRBRUP7f8NfbM+6jD6H17GMDPqFk/dwDY0NlD7YUx1rP/ALwNwFkA5wH8ZrvX49Breh2US8qjAF5U/70Niif+OICXATwGYKjda3Xo9b4RwNfV/98N4DkA5wD8CwBfu9dn87W9CsBh9b38GoDBXnsfAfxPAKcBHAfwfwH4uv19BPB5KHsYBShXcB8wet8AEJSsw/MAjkHJfGr7a2CMifYOAoFA0I/0su0jEAgEAgNE8BcIBII+RAR/gUAg6ENE8BcIBII+RAR/gUAg6ENE8BcIBII+RAR/gUAg6EP+f3yptQAuVLCtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a_list = [1, 2, 3]\n",
    "\n",
    "position_of_three = a_list.index(3)\n",
    "\n",
    "print(position_of_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a_list.index(i) for i in a_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
