{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "#env = gym.make(\"FrozenLake-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = gym.make(\"FrozenLake-v0\").env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP, DOWN, LEFT, RIGHT = range(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = lambda s: {\n",
    "    0:LEFT, 1:LEFT, 2:LEFT, 3:UP, 4:LEFT,\n",
    "    5:LEFT, 6:LEFT, 7:LEFT, 8:UP, 9:LEFT,\n",
    "    10:LEFT, 11:LEFT, 12:LEFT, 13:LEFT, 14:LEFT,\n",
    "    15:LEFT\n",
    "}[s] #the added[s] makes pi(the dictionary) callable, takes key as argument and returns value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, 8, 0.0, False),\n",
       " (0.3333333333333333, 12, 0.0, True),\n",
       " (0.3333333333333333, 9, 0.0, False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[8][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def policy_evaluation(pi, P, gamma = 1.0, theta=1e-10):\n",
    "    prev_V = np.zeros(len(P))\n",
    "    while True:\n",
    "        V = np.zeros(len(P))\n",
    "        for s in range(len(P)):\n",
    "            for prob, next_state, reward, done in P[s][pi(s)]:\n",
    "                V[s]+=prob*(reward + gamma * prev_V[next_state] * (not done))\n",
    "        if np.max(np.abs(prev_V - V)) < theta:\n",
    "            break\n",
    "        prev_V = V.copy()\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(V, P, gamma = 1.0):\n",
    "    Q_table = np.zeros((len(P), len(P[0])))\n",
    "    print(Q_table.shape)\n",
    "    for s in range(len(P)):\n",
    "        for a in range(len(P[s])):\n",
    "            for probs, next_state, reward, done in P[s][a]:\n",
    "                Q_table[s][a]+=probs*(reward + gamma*V[next_state]*(not done))\n",
    "    new_pi = lambda s : {s:a for s, a in enumerate(np.argmax(Q_table, axis=1))}[s]\n",
    "    return new_pi,Q_table\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02155172, 0.03448276, 0.06896552, 0.03448276, 0.00862069,\n",
       "       0.        , 0.10344828, 0.        , 0.00431034, 0.22068966,\n",
       "       0.24137931, 0.        , 0.        , 0.42068966, 0.62068966,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_ = policy_evaluation(pi, P, gamma = 1.0, theta=1e-10)\n",
    "pol_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4)\n"
     ]
    }
   ],
   "source": [
    "new_pi, qt_ = policy_improvement(pol_, P, gamma = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01724138, 0.02155172, 0.02155172, 0.02586207],\n",
       "       [0.01867816, 0.03017241, 0.03448276, 0.04166667],\n",
       "       [0.06896552, 0.05747126, 0.06896552, 0.04597701],\n",
       "       [0.03448276, 0.03448276, 0.02298851, 0.04597701],\n",
       "       [0.01149425, 0.00431034, 0.00862069, 0.01005747],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.10344828, 0.08045977, 0.10344828, 0.02298851],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.00431034, 0.075     , 0.07643678, 0.07787356],\n",
       "       [0.14166667, 0.22212644, 0.22068966, 0.08189655],\n",
       "       [0.31494253, 0.28045977, 0.24137931, 0.10804598],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.2137931 , 0.34712644, 0.42068966, 0.28045977],\n",
       "       [0.42758621, 0.68045977, 0.62068966, 0.55402299],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(qt_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qt_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 3,\n",
       " 1: 3,\n",
       " 2: 0,\n",
       " 3: 3,\n",
       " 4: 0,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 0,\n",
       " 8: 3,\n",
       " 9: 1,\n",
       " 10: 0,\n",
       " 11: 0,\n",
       " 12: 0,\n",
       " 13: 2,\n",
       " 14: 1,\n",
       " 15: 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{s:a for s, a in enumerate(np.argmax(qt_, axis=1))} # enumerate just allows a counter to be automatically added when looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 3\n",
      "2 0\n",
      "3 3\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 3\n",
      "9 1\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 2\n",
      "14 1\n",
      "15 0\n"
     ]
    }
   ],
   "source": [
    "for s, a in enumerate(np.argmax(qt_, axis=1)):\n",
    "    print(s,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29787234, 0.29787234, 0.29787234, 0.29787234, 0.40425532,\n",
       "       0.        , 0.29787234, 0.        , 0.5106383 , 0.61702128,\n",
       "       0.59574468, 0.        , 0.        , 0.74468085, 0.87234043,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_evaluation(new_pi, P, gamma = 1.0, theta=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.policy_improvement.<locals>.<lambda>(s)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_actions = np.random.choice(tuple(P[0].keys()), len(P))\n",
    "def policy_iteration(P, gamma=1.0, theta=1e-10):\n",
    "    random_actions = np.random.choice(tuple(P[0].keys()), len(P))#generate random policy for each state\n",
    "    \n",
    "    policy_ = lambda s : {s:a for s, a in enumerate(random_actions)}[s] #create dictionary func taking key as arg return value/action\n",
    "    print(type(policy_(0)))\n",
    "    while True:\n",
    "        old_pi = {s:policy_(s) for s in range(len(P))}\n",
    "        V  = policy_evaluation(policy_, P, gamma, theta)\n",
    "        \n",
    "        policy_,_ = policy_improvement(V, P, gamma) #a 'new improved' policy is created based off old state value func following policy pie\n",
    "        \n",
    "        print(type(policy_(0)))\n",
    "        if old_pi == {s:policy_(s) for s in range(len(P))}:\n",
    "            break\n",
    "    return V, policy_,_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int32'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n",
      "(16, 4)\n",
      "<class 'numpy.int64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.82352941, 0.82352941, 0.82352941, 0.82352941, 0.82352941,\n",
       "        0.        , 0.52941176, 0.        , 0.82352941, 0.82352941,\n",
       "        0.76470588, 0.        , 0.        , 0.88235294, 0.94117647,\n",
       "        0.        ]),\n",
       " <function __main__.policy_improvement.<locals>.<lambda>(s)>,\n",
       " array([[0.82352941, 0.82352941, 0.82352941, 0.82352941],\n",
       "        [0.54901961, 0.54901961, 0.54901961, 0.82352941],\n",
       "        [0.72549019, 0.72549019, 0.72549019, 0.82352941],\n",
       "        [0.54901961, 0.54901961, 0.54901961, 0.82352941],\n",
       "        [0.82352941, 0.54901961, 0.54901961, 0.54901961],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.52941176, 0.25490196, 0.52941176, 0.2745098 ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.54901961, 0.54901961, 0.54901961, 0.82352941],\n",
       "        [0.56862745, 0.82352941, 0.54901961, 0.52941176],\n",
       "        [0.76470588, 0.58823529, 0.49019608, 0.45098039],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.56862745, 0.60784314, 0.88235294, 0.58823529],\n",
       "        [0.8627451 , 0.94117647, 0.90196078, 0.88235294],\n",
       "        [0.        , 0.        , 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_iteration(P, gamma=1.0, theta=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_actions(no) - this is VALUE ITERATION. no policy is explicitly described - greedy actions are taken and are used\n",
    "#to update value of a state\n",
    "def value_iteration(P, gamma = 1.0, theta = 1e-10):\n",
    "    V = np.zeros(len(P))\n",
    "    \n",
    "    while True:\n",
    "        Q_table = np.zeros((len(P), len(P[0])))\n",
    "        \n",
    "        for s in range(len(P)):\n",
    "            for a in range(len(P[0])):\n",
    "                for prob, next_state, reward, done in P[s][a]:\n",
    "                    Q_table[s][a] = prob * (reward + gamma*V[next_state]*(not done))\n",
    "        \n",
    "        if np.max(np.abs(V - np.max(Q_table, axis = 1))) < theta:\n",
    "            break\n",
    "        \n",
    "        V = np.max(Q_table, axis = 1)\n",
    "    \n",
    "    policy_ = lambda s : {s:a for s, a in enumerate(np.argmax(Q_table, axis=1))}[s]\n",
    "    \n",
    "    return V, policy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00137174, 0.00411523, 0.01234568, 0.00411523, 0.00411523,\n",
       "        0.        , 0.03703704, 0.        , 0.01234568, 0.03703704,\n",
       "        0.11111111, 0.        , 0.        , 0.11111111, 0.33333333,\n",
       "        0.        ]),\n",
       " <function __main__.value_iteration.<locals>.<lambda>(s)>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_iteration(P, gamma = 1.0, theta = 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = np.zeros((len(P), len(P[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected sequence object with len >= 0 or a single integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6fda1342fbb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expected sequence object with len >= 0 or a single integer"
     ]
    }
   ],
   "source": [
    "V = np.zeros(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
